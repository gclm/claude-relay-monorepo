/**
 * Claude Proxy OpenAI é›†æˆæµ‹è¯•
 * æ¨¡æ‹ŸçœŸå®çš„ç¼–ç¨‹åœºæ™¯ï¼Œæµ‹è¯• Claude-to-OpenAI è½¬æ¢å™¨
 * åŒ…å«å·¥å…·è°ƒç”¨ã€æµå¼å“åº”ç­‰å®Œæ•´åœºæ™¯
 */

import { describe, test, expect, beforeEach } from 'vitest'
import { createTestApp, createTestRequest } from '../../../helpers'

describe('Claude Proxy OpenAI é›†æˆæµ‹è¯•', () => {
  let testApp: ReturnType<typeof createTestApp>

  beforeEach(() => {
    testApp = createTestApp()
    console.log('ğŸ§ª åˆå§‹åŒ–æµ‹è¯•åº”ç”¨ï¼Œè¿æ¥ OpenAI API')
  })

  test('å¥åº·æ£€æŸ¥', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šç³»ç»Ÿå¥åº·æ£€æŸ¥')
    
    const request = createTestRequest('/v1/health')
    const response = await testApp.request(request)
    
    expect(response.status).toBe(200)
    console.log('âœ… ç³»ç»Ÿå¥åº·æ£€æŸ¥é€šè¿‡')
  })

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šä»£ç è°ƒè¯•', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šä»£ç è°ƒè¯•åœºæ™¯')
    
    const debugRequest = {
      model: 'claude-3-5-sonnet-20241022', // è·¯ç”±åˆ° OpenAI GPT-4
      messages: [
        {
          role: 'user',
          content: `æˆ‘çš„ Python å‡½æ•°æœ‰é—®é¢˜ï¼Œè¯·å¸®æˆ‘è°ƒè¯•ï¼š

\`\`\`python
def process_orders(orders):
    total_revenue = 0
    processed_orders = []
    
    for order in orders:
        if order['status'] == 'pending':
            # è®¡ç®—è®¢å•æ€»ä»·
            order_total = 0
            for item in order['items']:
                order_total += item['price'] * item['quantity']
            
            # åº”ç”¨æŠ˜æ‰£
            if order['discount'] > 0:
                order_total = order_total * (1 - order['discount'])
            
            processed_orders.append({
                'id': order['id'],
                'total': order_total,
                'status': 'processed'
            })
            
            total_revenue += order_total
    
    return total_revenue, processed_orders

# æµ‹è¯•æ•°æ®
orders = [
    {
        'id': 1,
        'status': 'pending',
        'items': [
            {'price': 100, 'quantity': 2},
            {'price': 50, 'quantity': 1}
        ],
        'discount': 0.1
    },
    {
        'id': 2,
        'status': 'completed',
        'items': [{'price': 200, 'quantity': 1}]
    }
]

revenue, processed = process_orders(orders)
print(f"Total revenue: {revenue}")
\`\`\`

è¿™ä¸ªå‡½æ•°é€»è¾‘æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿè¯·æŒ‡å‡ºæ½œåœ¨çš„ bug å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚`
        }
      ]
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(debugRequest)
    })

    console.log('ğŸ“¤ å‘é€ä»£ç è°ƒè¯•è¯·æ±‚åˆ° OpenAI')
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    expect(response.status).toBe(200)
    
    const responseText = await response.text()
    console.log('ğŸ“Š å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
    
    // æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«è°ƒè¯•ç›¸å…³å†…å®¹
    const hasDebuggingContent = responseText.includes('discount') || 
                               responseText.includes('KeyError') || 
                               responseText.includes('é”™è¯¯') ||
                               responseText.includes('bug') ||
                               responseText.includes('æ”¹è¿›')
    
    if (hasDebuggingContent) {
      console.log('âœ… OpenAI æˆåŠŸè¯†åˆ«å¹¶è°ƒè¯•äº†ä»£ç é—®é¢˜')
    }
    
    console.log('ğŸ“ å“åº”é¢„è§ˆ:', responseText.substring(0, 500) + '...')
  }, 30000)

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šå·¥å…·è°ƒç”¨ - ä»£ç æ‰§è¡Œ', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šå·¥å…·è°ƒç”¨ä»£ç æ‰§è¡Œåœºæ™¯')
    
    const toolCallRequest = {
      model: 'claude-3-5-sonnet-20241022',
      messages: [
        {
          role: 'user',
          content: 'è¯·å¸®æˆ‘è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬10é¡¹ï¼Œå¹¶è§£é‡Šç®—æ³•å¤æ‚åº¦ã€‚ä½ å¯ä»¥ä½¿ç”¨ä»£ç æ‰§è¡Œå·¥å…·æ¥éªŒè¯ç»“æœã€‚'
        }
      ],
      tools: [
        {
          name: 'execute_python',
          description: 'æ‰§è¡Œ Python ä»£ç å¹¶è¿”å›ç»“æœ',
          input_schema: {
            type: 'object',
            properties: {
              code: {
                type: 'string',
                description: 'è¦æ‰§è¡Œçš„ Python ä»£ç '
              }
            },
            required: ['code']
          }
        },
        {
          name: 'analyze_complexity',
          description: 'åˆ†æç®—æ³•æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦',
          input_schema: {
            type: 'object',
            properties: {
              algorithm_name: {
                type: 'string',
                description: 'ç®—æ³•åç§°'
              },
              code: {
                type: 'string',
                description: 'ç®—æ³•ä»£ç '
              }
            },
            required: ['algorithm_name', 'code']
          }
        }
      ],
      tool_choice: 'auto'
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(toolCallRequest)
    })

    console.log('ğŸ“¤ å‘é€å·¥å…·è°ƒç”¨è¯·æ±‚åˆ° OpenAI')
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    expect(response.status).toBe(200)
    
    const responseText = await response.text()
    console.log('ğŸ“Š å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
    
    // æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
    const hasToolCall = responseText.includes('tool_use') || 
                       responseText.includes('execute_python') ||
                       responseText.includes('analyze_complexity')
    
    if (hasToolCall) {
      console.log('âœ… OpenAI æˆåŠŸç”Ÿæˆäº†å·¥å…·è°ƒç”¨')
    }
    
    console.log('ğŸ“ å·¥å…·è°ƒç”¨å“åº”é¢„è§ˆ:', responseText.substring(0, 800) + '...')
  }, 30000)

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šå¤šæ­¥éª¤å·¥å…·è°ƒç”¨', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šå¤šæ­¥éª¤å·¥å…·è°ƒç”¨åœºæ™¯')
    
    // ç¬¬ä¸€æ­¥ï¼šå‘é€åŒ…å«å·¥å…·è°ƒç”¨çš„è¯·æ±‚
    const initialRequest = {
      model: 'claude-3-5-sonnet-20241022',
      messages: [
        {
          role: 'user',
          content: 'è¯·å¸®æˆ‘è®¾è®¡ä¸€ä¸ªç®€å•çš„ç”¨æˆ·ç®¡ç†ç³»ç»Ÿçš„æ•°æ®åº“è¡¨ç»“æ„ï¼Œç„¶åç”Ÿæˆå¯¹åº”çš„ SQL åˆ›å»ºè¯­å¥ã€‚'
        }
      ],
      tools: [
        {
          name: 'design_database_schema',
          description: 'è®¾è®¡æ•°æ®åº“è¡¨ç»“æ„',
          input_schema: {
            type: 'object',
            properties: {
              table_name: {
                type: 'string',
                description: 'è¡¨å'
              },
              columns: {
                type: 'array',
                items: {
                  type: 'object',
                  properties: {
                    name: { type: 'string' },
                    type: { type: 'string' },
                    constraints: { type: 'array', items: { type: 'string' } }
                  }
                },
                description: 'è¡¨åˆ—å®šä¹‰'
              }
            },
            required: ['table_name', 'columns']
          }
        },
        {
          name: 'generate_sql',
          description: 'æ ¹æ®è¡¨ç»“æ„ç”Ÿæˆ SQL è¯­å¥',
          input_schema: {
            type: 'object',
            properties: {
              operation: {
                type: 'string',
                enum: ['CREATE_TABLE', 'INSERT', 'SELECT', 'UPDATE', 'DELETE']
              },
              table_schema: {
                type: 'object',
                description: 'è¡¨ç»“æ„å®šä¹‰'
              }
            },
            required: ['operation', 'table_schema']
          }
        }
      ]
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(initialRequest)
    })

    console.log('ğŸ“¤ å‘é€å¤šæ­¥éª¤å·¥å…·è°ƒç”¨è¯·æ±‚åˆ° OpenAI')
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    expect(response.status).toBe(200)
    
    const responseText = await response.text()
    console.log('ğŸ“Š å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
    
    // è§£æå“åº”ï¼Œæ£€æŸ¥å·¥å…·è°ƒç”¨
    const hasDesignTool = responseText.includes('design_database_schema')
    const hasGenerateTool = responseText.includes('generate_sql')
    
    if (hasDesignTool || hasGenerateTool) {
      console.log('âœ… OpenAI æˆåŠŸç”Ÿæˆäº†æ•°æ®åº“ç›¸å…³çš„å·¥å…·è°ƒç”¨')
    }
    
    console.log('ğŸ“ å¤šæ­¥éª¤å·¥å…·è°ƒç”¨å“åº”é¢„è§ˆ:', responseText.substring(0, 600) + '...')
  }, 30000)

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šå¸¦å·¥å…·ç»“æœçš„å¯¹è¯', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šå¸¦å·¥å…·ç»“æœçš„å®Œæ•´å¯¹è¯åœºæ™¯')
    
    const conversationWithToolsRequest = {
      model: 'claude-3-5-sonnet-20241022',
      messages: [
        {
          role: 'user',
          content: 'è¯·å¸®æˆ‘åˆ†æä¸€ä¸ª API çš„æ€§èƒ½ï¼Œæ£€æŸ¥å“åº”æ—¶é—´æ˜¯å¦æ­£å¸¸ã€‚'
        },
        {
          role: 'assistant',
          content: [
            {
              type: 'text',
              text: 'æˆ‘æ¥å¸®ä½ åˆ†æ API æ€§èƒ½ã€‚è®©æˆ‘å…ˆæ£€æŸ¥ä¸€ä¸‹ API çš„å“åº”æ—¶é—´ã€‚'
            },
            {
              type: 'tool_use',
              id: 'toolu_api_check_001',
              name: 'check_api_performance',
              input: {
                url: 'https://jsonplaceholder.typicode.com/posts/1',
                method: 'GET',
                timeout: 5000
              }
            }
          ]
        },
        {
          role: 'user',
          content: [
            {
              type: 'tool_result',
              tool_use_id: 'toolu_api_check_001',
              content: JSON.stringify({
                status_code: 200,
                response_time_ms: 245,
                content_length: 292,
                headers: {
                  'content-type': 'application/json; charset=utf-8',
                  'cache-control': 'max-age=43200'
                }
              })
            }
          ]
        },
        {
          role: 'user',
          content: 'æ ¹æ®æ£€æŸ¥ç»“æœï¼Œè¿™ä¸ª API çš„æ€§èƒ½æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆä¼˜åŒ–å»ºè®®å—ï¼Ÿ'
        }
      ],
      tools: [
        {
          name: 'check_api_performance',
          description: 'æ£€æŸ¥ API æ€§èƒ½æŒ‡æ ‡',
          input_schema: {
            type: 'object',
            properties: {
              url: { type: 'string' },
              method: { type: 'string' },
              timeout: { type: 'number' }
            },
            required: ['url', 'method']
          }
        },
        {
          name: 'suggest_optimization',
          description: 'åŸºäºæ€§èƒ½æ•°æ®æä¾›ä¼˜åŒ–å»ºè®®',
          input_schema: {
            type: 'object',
            properties: {
              performance_data: { type: 'object' },
              target_response_time: { type: 'number' }
            },
            required: ['performance_data']
          }
        }
      ]
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(conversationWithToolsRequest)
    })

    console.log('ğŸ“¤ å‘é€å¸¦å·¥å…·ç»“æœçš„å¯¹è¯è¯·æ±‚åˆ° OpenAI')
    console.log('ğŸ’¬ æ¶ˆæ¯æ•°é‡:', conversationWithToolsRequest.messages.length)
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    expect(response.status).toBe(200)
    
    const responseText = await response.text()
    console.log('ğŸ“Š å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
    
    // æ£€æŸ¥æ˜¯å¦ç†è§£äº†å·¥å…·ç»“æœå¹¶æä¾›åˆ†æ
    const hasAnalysis = responseText.includes('245') || 
                       responseText.includes('æ¯«ç§’') || 
                       responseText.includes('æ€§èƒ½') ||
                       responseText.includes('ä¼˜åŒ–') ||
                       responseText.includes('å»ºè®®')
    
    if (hasAnalysis) {
      console.log('âœ… OpenAI æˆåŠŸç†è§£å·¥å…·ç»“æœå¹¶æä¾›äº†æ€§èƒ½åˆ†æ')
    }
    
    console.log('ğŸ“ å·¥å…·ç»“æœåˆ†æå“åº”:', responseText.substring(0, 700) + '...')
  }, 30000)

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šæµå¼å“åº”ä¸å·¥å…·è°ƒç”¨', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šæµå¼å“åº”å·¥å…·è°ƒç”¨åœºæ™¯')
    
    const streamToolRequest = {
      model: 'claude-3-5-sonnet-20241022',
      stream: true,
      messages: [
        {
          role: 'user',
          content: 'è¯·å¸®æˆ‘åˆ›å»ºä¸€ä¸ª Node.js Express æœåŠ¡å™¨çš„åŸºæœ¬ç»“æ„ï¼ŒåŒ…æ‹¬è·¯ç”±å’Œä¸­é—´ä»¶é…ç½®ã€‚'
        }
      ],
      tools: [
        {
          name: 'generate_express_app',
          description: 'ç”Ÿæˆ Express åº”ç”¨ç¨‹åºç»“æ„',
          input_schema: {
            type: 'object',
            properties: {
              app_name: { type: 'string' },
              routes: {
                type: 'array',
                items: { type: 'string' }
              },
              middleware: {
                type: 'array',
                items: { type: 'string' }
              }
            },
            required: ['app_name']
          }
        }
      ]
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(streamToolRequest)
    })

    console.log('ğŸ“¤ å‘é€æµå¼å·¥å…·è°ƒç”¨è¯·æ±‚åˆ° OpenAI')
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    console.log('ğŸ“¥ å“åº”å¤´:', Object.fromEntries(response.headers.entries()))
    
    if (response.status === 200) {
      expect(response.headers.get('Content-Type')).toContain('text/event-stream')
      console.log('âœ… æ­£ç¡®è®¾ç½®äº†æµå¼å“åº”å¤´')
      
      const responseText = await response.text()
      console.log('ğŸ“Š æµå¼å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
      
      // æ£€æŸ¥ SSE æ ¼å¼å’Œå·¥å…·è°ƒç”¨
      const hasSSEFormat = responseText.includes('data:') && responseText.includes('event:')
      const hasToolCall = responseText.includes('tool_use') || responseText.includes('generate_express_app')
      
      if (hasSSEFormat) {
        console.log('âœ… æ£€æµ‹åˆ°æ­£ç¡®çš„ SSE æ ¼å¼')
      }
      
      if (hasToolCall) {
        console.log('âœ… æ£€æµ‹åˆ°æµå¼å·¥å…·è°ƒç”¨')
      }
      
      console.log('ğŸ“ æµå¼å·¥å…·è°ƒç”¨å“åº”å¼€å¤´:', responseText.substring(0, 400) + '...')
    }
  }, 30000)

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šå¤æ‚æ•°æ®åˆ†æ', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šå¤æ‚æ•°æ®åˆ†æåœºæ™¯')
    
    const dataAnalysisRequest = {
      model: 'claude-3-5-sonnet-20241022',
      messages: [
        {
          role: 'user',
          content: `è¯·åˆ†æè¿™ä¸ªç”µå•†ç½‘ç«™çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œå¹¶æä¾›ä¼˜åŒ–å»ºè®®ï¼š

\`\`\`json
{
  "period": "2024-01-01 to 2024-01-31",
  "metrics": {
    "total_users": 15420,
    "new_users": 3245,
    "returning_users": 12175,
    "bounce_rate": 0.67,
    "avg_session_duration": 245,
    "page_views": 89234,
    "conversion_rate": 0.023,
    "revenue": 156780
  },
  "top_pages": [
    {"path": "/", "views": 23456, "avg_time": 45},
    {"path": "/products", "views": 18234, "avg_time": 120},
    {"path": "/product/123", "views": 8945, "avg_time": 180},
    {"path": "/cart", "views": 4567, "avg_time": 90},
    {"path": "/checkout", "views": 2341, "avg_time": 210}
  ],
  "user_flow": {
    "home_to_products": 0.78,
    "products_to_cart": 0.25,
    "cart_to_checkout": 0.51,
    "checkout_to_complete": 0.45
  }
}
\`\`\`

è¯·åˆ†æå…³é”®æŒ‡æ ‡ï¼Œè¯†åˆ«é—®é¢˜ç‚¹ï¼Œå¹¶æä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®ã€‚`
        }
      ]
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(dataAnalysisRequest)
    })

    console.log('ğŸ“¤ å‘é€æ•°æ®åˆ†æè¯·æ±‚åˆ° OpenAI')
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    expect(response.status).toBe(200)
    
    const responseText = await response.text()
    console.log('ğŸ“Š å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
    
    // æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°æ®åˆ†æç›¸å…³å†…å®¹
    const hasDataAnalysis = responseText.includes('è·³å‡ºç‡') || 
                           responseText.includes('è½¬åŒ–ç‡') || 
                           responseText.includes('67%') ||
                           responseText.includes('2.3%') ||
                           responseText.includes('ä¼˜åŒ–')
    
    if (hasDataAnalysis) {
      console.log('âœ… OpenAI æˆåŠŸåˆ†æäº†æ•°æ®å¹¶æä¾›äº†ä¼˜åŒ–å»ºè®®')
    }
    
    console.log('ğŸ“ æ•°æ®åˆ†æå“åº”é¢„è§ˆ:', responseText.substring(0, 600) + '...')
  }, 30000)

  test('ç¼–ç¨‹åŠ©æ‰‹åœºæ™¯ï¼šå¤šè½®æŠ€æœ¯å¯¹è¯', async () => {
    console.log('ğŸ” æµ‹è¯•ï¼šå¤šè½®æŠ€æœ¯å¯¹è¯åœºæ™¯')
    
    const multiTurnRequest = {
      model: 'claude-3-5-sonnet-20241022',
      messages: [
        {
          role: 'user',
          content: 'æˆ‘æƒ³åœ¨æˆ‘çš„ React åº”ç”¨ä¸­å®ç°æ— é™æ»šåŠ¨åŠŸèƒ½ï¼Œæœ‰ä»€ä¹ˆå¥½çš„æ–¹æ¡ˆï¼Ÿ'
        },
        {
          role: 'assistant',
          content: 'å®ç°æ— é™æ»šåŠ¨æœ‰å‡ ç§å¸¸ç”¨æ–¹æ¡ˆï¼š\n\n1. **Intersection Observer API** - ç°ä»£æµè§ˆå™¨æ¨èæ–¹æ¡ˆ\n2. **scroll äº‹ä»¶ç›‘å¬** - ä¼ ç»Ÿæ–¹æ¡ˆï¼Œå…¼å®¹æ€§æ›´å¥½\n3. **ä½¿ç”¨ç°æˆåº“** - å¦‚ react-infinite-scroll-component\n\næˆ‘æ¨èä½¿ç”¨ Intersection Observer APIï¼Œå®ƒæ€§èƒ½æ›´å¥½ï¼Œä¸ä¼šé¢‘ç¹è§¦å‘äº‹ä»¶ã€‚ä½ çš„åº”ç”¨ä¸»è¦å±•ç¤ºä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Ÿè¿™æ ·æˆ‘å¯ä»¥æä¾›æ›´å…·ä½“çš„å®ç°å»ºè®®ã€‚'
        },
        {
          role: 'user',
          content: 'ä¸»è¦æ˜¯å±•ç¤ºæ–°é—»æ–‡ç« åˆ—è¡¨ï¼Œæ¯æ¬¡åŠ è½½20æ¡ï¼Œæ•°æ®ä» REST API è·å–ã€‚è¯·æä¾›ä¸€ä¸ªå…·ä½“çš„å®ç°ç¤ºä¾‹ã€‚'
        },
        {
          role: 'assistant',
          content: 'å¥½çš„ï¼Œæˆ‘æ¥ä¸ºä½ åˆ›å»ºä¸€ä¸ªæ–°é—»æ–‡ç« æ— é™æ»šåŠ¨çš„å®Œæ•´ç¤ºä¾‹ï¼š\n\n```jsx\nimport React, { useState, useEffect, useCallback, useRef } from \'react\';\n\nconst NewsInfiniteScroll = () => {\n  const [articles, setArticles] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [page, setPage] = useState(1);\n  const [hasMore, setHasMore] = useState(true);\n  const observer = useRef();\n\n  // API è°ƒç”¨å‡½æ•°\n  const fetchArticles = async (pageNum) => {\n    setLoading(true);\n    try {\n      const response = await fetch(`/api/news?page=${pageNum}&limit=20`);\n      const data = await response.json();\n      return data;\n    } catch (error) {\n      console.error(\'Error fetching articles:\', error);\n      return { articles: [], hasMore: false };\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // åŠ è½½æ›´å¤šæ–‡ç« \n  const loadMore = useCallback(async () => {\n    if (loading || !hasMore) return;\n    \n    const data = await fetchArticles(page);\n    setArticles(prev => [...prev, ...data.articles]);\n    setHasMore(data.hasMore);\n    setPage(prev => prev + 1);\n  }, [page, loading, hasMore]);\n\n  // Intersection Observer å›è°ƒ\n  const lastArticleRef = useCallback(node => {\n    if (loading) return;\n    if (observer.current) observer.current.disconnect();\n    \n    observer.current = new IntersectionObserver(entries => {\n      if (entries[0].isIntersecting && hasMore) {\n        loadMore();\n      }\n    });\n    \n    if (node) observer.current.observe(node);\n  }, [loading, hasMore, loadMore]);\n\n  // åˆå§‹åŠ è½½\n  useEffect(() => {\n    loadMore();\n  }, []);\n\n  return (\n    <div className=\"news-container\">\n      <h1>æœ€æ–°æ–°é—»</h1>\n      <div className=\"articles-list\">\n        {articles.map((article, index) => {\n          const isLast = index === articles.length - 1;\n          return (\n            <div \n              key={article.id}\n              ref={isLast ? lastArticleRef : null}\n              className=\"article-card\"\n            >\n              <h3>{article.title}</h3>\n              <p>{article.summary}</p>\n              <span className=\"publish-date\">{article.publishDate}</span>\n            </div>\n          );\n        })}\n      </div>\n      {loading && <div className=\"loading\">åŠ è½½ä¸­...</div>}\n      {!hasMore && <div className=\"end-message\">æ²¡æœ‰æ›´å¤šæ–‡ç« äº†</div>}\n    </div>\n  );\n};\n\nexport default NewsInfiniteScroll;\n```\n\nè¿™ä¸ªå®ç°çš„å…³é”®ç‚¹ï¼š\n1. ä½¿ç”¨ `useCallback` ä¼˜åŒ–æ€§èƒ½\n2. `lastArticleRef` åªé™„åŠ åˆ°æœ€åä¸€ä¸ªå…ƒç´ \n3. é˜²æ­¢é‡å¤åŠ è½½çš„é€»è¾‘\n4. é”™è¯¯å¤„ç†å’ŒåŠ è½½çŠ¶æ€ç®¡ç†\n\nä½ è¿˜éœ€è¦é…ç½®å¯¹åº”çš„ CSS æ ·å¼ï¼Œè¦æˆ‘ä¹Ÿæä¾›å—ï¼Ÿ'
        },
        {
          role: 'user',
          content: 'è¿™ä¸ªå®ç°å¾ˆå¥½ï¼ä½†æˆ‘æ‹…å¿ƒåœ¨å¿«é€Ÿæ»šåŠ¨æ—¶ä¼šæœ‰æ€§èƒ½é—®é¢˜ï¼Œæœ‰ä»€ä¹ˆä¼˜åŒ–å»ºè®®å—ï¼Ÿ'
        }
      ]
    }

    const request = createTestRequest('/v1/messages', {
      method: 'POST',
      body: JSON.stringify(multiTurnRequest)
    })

    console.log('ğŸ“¤ å‘é€å¤šè½®æŠ€æœ¯å¯¹è¯è¯·æ±‚åˆ° OpenAI')
    console.log('ğŸ’¬ æ¶ˆæ¯æ•°é‡:', multiTurnRequest.messages.length)
    
    const response = await testApp.request(request)
    
    console.log('ğŸ“¥ å“åº”çŠ¶æ€:', response.status)
    expect(response.status).toBe(200)
    
    const responseText = await response.text()
    console.log('ğŸ“Š å“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦')
    
    // æ£€æŸ¥æ˜¯å¦åŒ…å«æ€§èƒ½ä¼˜åŒ–ç›¸å…³å†…å®¹
    const hasOptimization = responseText.includes('æ€§èƒ½') || 
                           responseText.includes('ä¼˜åŒ–') || 
                           responseText.includes('è™šæ‹ŸåŒ–') ||
                           responseText.includes('èŠ‚æµ') ||
                           responseText.includes('debounce') ||
                           responseText.includes('React.memo')
    
    if (hasOptimization) {
      console.log('âœ… OpenAI åœ¨å¤šè½®å¯¹è¯ä¸­æ­£ç¡®ç†è§£äº†ä¸Šä¸‹æ–‡å¹¶æä¾›äº†æ€§èƒ½ä¼˜åŒ–å»ºè®®')
    }
    
    console.log('ğŸ“ æ€§èƒ½ä¼˜åŒ–å»ºè®®é¢„è§ˆ:', responseText.substring(0, 500) + '...')
  }, 30000)
})